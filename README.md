# PAIR Interpretability

This repo contains code and articles on [PAIR](https://ai.google/pair) interpretability projects.

### Scalable Influence and Fact Tracing for Large Language Model Pretraining (ICLR'25)

See [blog post](https://medium.com/people-ai-research/scaling-training-data-attribution-f7d1eddd85da), for a light introduction to the paper. There is also [a public demo](https://github.com/PAIR-code/pretraining-tda/blob/main/demo/README.md), and the dedicated [github repo](https://github.com/PAIR-code/pretraining-tda). The full paper is [Scalable Influence and Fact Tracing for Large Language Model Pretraining](https://arxiv.org/abs/2410.17413) -- Tyler Chang, Dheeraj Rajagopal, Tolga Bolukbasi, Lucas Dixon, Ian Tenney (RH)

### Racing Thoughts: Explaining Large Language Model Contextualization Errors (NAACL'25)

[Racing Thoughts: Explaining Contextualization Errors Within Large Language Models](https://arxiv.org/abs/2410.02102) -- Michael A. Lepori, Mike Mozer, Asma Ghandeharioun (RH)

### Who's asking? User personas and the mechanics of latent misalignment (NeurIPS'24)

[Who's asking? User personas and the mechanics of latent misalignment](https://arxiv.org/abs/2406.12094) -- Asma Ghandeharioun, Ann Yuan, Marius Guerard, Emily Reif, Michael A. Lepori, Lucas Dixon, at [NeurIPS'24](https://neurips.cc/virtual/2024/poster/94269).

### Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models (ICML'24)

The [Patchscopes mini-site](https://pair-code.github.io/interpretability/patchscopes) & the [interactive explorable](https://pair.withgoogle.com/explorables/patchscopes/) contain a brief introduction to the [longer paper](https://arxiv.org/abs/2401.06102) (ICML'24) by Asma Ghandeharioun, Ann Yuan, Marius Guerard, Emily Reif, Michael A. Lepori, Lucas Dixon.

### Visualizing and Measuring the Geometry of BERT
[bert-tree](https://github.com/PAIR-code/interpretability/tree/master/bert-tree) and [context-atlas](https://github.com/PAIR-code/interpretability/tree/master/context-atlas) are repos for two interactive blogposts/visualizations for the paper [Visualizing and Measuring the Geometry of BERT
](https://arxiv.org/abs/1906.02715):

1. [Language, trees, and geometry in neural networks](https://pair-code.github.io/interpretability/bert-tree/) explores the geometry of syntactic information in BERT ([bert-tree](https://github.com/PAIR-code/interpretability/tree/master/bert-tree))

2. [Language, Context, and Geometry in Neural Network](https://pair-code.github.io/interpretability/bert-tree/) explores semantics and context in BERT. See the accompanying tool, [Context Atlas](https://storage.googleapis.com/bert-wsd-vis/demo/index.html?#word=lie), for more details ([context-atlas](https://github.com/PAIR-code/interpretability/tree/master/context-atlas))

### Deep dreaming on text
[text-dream](https://github.com/PAIR-code/interpretability/tree/master/text-dream) contains different experiments and tools to work with deep dreaming
for text.

### LinguisticLens
[data-synth-syntax](https://github.com/PAIR-code/interpretability/tree/master/data-synth-syntax) contains [LinguisticLens](https://storage.googleapis.com/data-synth-trees/demo/index.html), a tool for visualizing generated text data.
